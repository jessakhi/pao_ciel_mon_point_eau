{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e387a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import rasterio\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ee67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e833fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to see what object you have when you read the images : \n",
    "# # Sentinel-2 image bands : {\"Blue\": 0, \"Green\": 1, \"Red\": 2, \"NIR\": 3, \"SWIR1\": 4, \"SWIR2\": 5} \n",
    "\n",
    "# with rasterio.open(\"/home/llalla/Documents/SWOT/tuto_unet/data_folder/s2/5_tile_2048_0.tif\") as src: \n",
    "#     s2_image = src.read()\n",
    "# s2_image = s2_image[:3, :, :]\n",
    "# s2_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd9e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, thumbnail_name, s1_image_folder, s2_image_folder, mask_folder):\n",
    "        self.thumbnail_name = thumbnail_name\n",
    "        self.s1_image_folder = s1_image_folder\n",
    "        self.s2_image_folder = s2_image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.thumbnail_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s1_image_path = os.path.join(self.s1_image_folder, self.thumbnail_name[idx])\n",
    "        s2_image_path = os.path.join(self.s2_image_folder, self.thumbnail_name[idx])\n",
    "        mask_path = os.path.join(self.mask_folder, self.thumbnail_name[idx])\n",
    "        \n",
    "        with rasterio.open(s1_image_path) as src: \n",
    "            s1_image = src.read()\n",
    "                                     \n",
    "        with rasterio.open(s2_image_path) as src: \n",
    "            s2_image = src.read()\n",
    "            s2_image = s2_image[:3, :, :] # keep only first 3 visible bands (RGB). Yan can also keep the 6 bands. \n",
    "                               \n",
    "        with rasterio.open(mask_path) as src: \n",
    "            mask = src.read()\n",
    "        mask = mask.astype('float32')\n",
    "        \n",
    "        # early fusion \n",
    "        image = np.concatenate((s1_image, s2_image), axis = 0)\n",
    "        \n",
    "        return torch.from_numpy(image),torch.from_numpy(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec8319",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/home/llalla/Documents/SWOT/tuto_unet/data_folder/\"\n",
    "s1_image_folder = data_folder + \"s1\"\n",
    "s2_image_folder = data_folder + \"s2\"\n",
    "mask_folder = data_folder + \"masks\"\n",
    "\n",
    "# thumbnails all have the same name : s1, s2, mask\n",
    "thumbnails = os.listdir(s1_image_folder)\n",
    "train_images, test_images = train_test_split(thumbnails, test_size=0.2, random_state=42)                                                    \n",
    "test_images, val_images = train_test_split(test_images, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_images), len(test_images), len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d794ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset(train_images, s1_image_folder, s2_image_folder, mask_folder)\n",
    "testset = Dataset(test_images, s1_image_folder, s2_image_folder, mask_folder)\n",
    "valset = Dataset(val_images, s1_image_folder, s2_image_folder, mask_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b26eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "test_batch_size = 8\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size= train_batch_size, num_workers= 2, shuffle= True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size= val_batch_size, num_workers= 2, shuffle= True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size= test_batch_size, num_workers= 2, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.down = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=False):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "                                    nn.Conv2d(in_channels, in_channels // 2, 1))\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, 2, stride=2)\n",
    "            \n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201093ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.up1 = Up(1024, 512)\n",
    "        self.up2 = Up(512, 256)\n",
    "        self.up3 = Up(256, 128)\n",
    "        self.up4 = Up(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x4, x3)\n",
    "        x = self.up3(x3, x2)\n",
    "        x = self.up4(x2, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b848d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DICE_BCE_Loss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        intersection = 2*(logits * targets).sum() + self.smooth\n",
    "        union = (logits + targets).sum() + self.smooth\n",
    "        dice_loss = 1. - intersection / union\n",
    "\n",
    "        loss = nn.BCELoss()\n",
    "        bce_loss = loss(logits, targets)\n",
    "\n",
    "        return dice_loss + bce_loss\n",
    "    \n",
    "def dice_coeff(logits, targets):\n",
    "    intersection = 2*(logits * targets).sum()\n",
    "    union = (logits + targets).sum()\n",
    "    if union == 0:\n",
    "        return 1\n",
    "    dice_coeff = intersection / union\n",
    "    return dice_coeff.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, loss, epochs=10):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_dices, val_dices = [], []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_dice = 0\n",
    "        for i, (images, masks) in enumerate(trainloader):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(images)\n",
    "            l = loss(logits, masks)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += l.item()\n",
    "            train_dice += dice_coeff(logits, masks)\n",
    "        train_loss /= len(trainloader)\n",
    "        train_dice /= len(trainloader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_dices.append(train_dice)\n",
    "        \n",
    "        #Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_dice = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, masks) in enumerate(valloader):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                logits = model(images)\n",
    "                l = loss(logits, masks)\n",
    "                val_loss += l.item()\n",
    "                val_dice += dice_coeff(logits, masks)\n",
    "        val_loss /= len(valloader)\n",
    "        val_dice /= len(valloader)\n",
    "        val_losses.append(val_loss)\n",
    "        val_dices.append(val_dice)\n",
    "        print(f\"Epoch: {epoch + 1}  Train Loss: {train_loss:.4f} | Train DICE Coeff: {train_dice:.4f} | Val Loss: {val_loss:.4f} | Val DICE Coeff: {val_dice:.4f}\")\n",
    "        \n",
    "    return train_losses, train_dices, val_losses, val_dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a85b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "loss = DICE_BCE_Loss()\n",
    "model = UNet(5, 1).to(device) # 5 for 3 optical bands + 2 radars. Could also be 8 si keep 6 optical bands. \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_dices, val_losses, val_dices = train(model, trainloader, optimizer, loss, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408c461",
   "metadata": {},
   "source": [
    "# Visualise Loss and DICE during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(epochs), train_dices)\n",
    "plt.plot(np.arange(epochs), val_dices)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"DICE Coeff\")\n",
    "plt.legend([\"Train DICE\", \"Val DICE\"])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(epochs), train_losses)\n",
    "plt.plot(np.arange(epochs), val_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train Loss\", \"Val Loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60066d2",
   "metadata": {},
   "source": [
    "# Visualise test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d303c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(testloader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(images.to(device)).cpu().detach()\n",
    "    pred = pred > 0.5\n",
    "\n",
    "def display_batch(images, masks, pred):\n",
    "    # move axis for plotting with matplotlib\n",
    "    images = images.permute(0, 2, 3, 1)\n",
    "    masks = masks.permute(0, 2, 3, 1)\n",
    "    pred = pred.permute(0, 2, 3, 1)\n",
    "\n",
    "    # convert from tensor to numpy array\n",
    "    images = images.numpy()\n",
    "    masks = masks.numpy()\n",
    "    pred = pred.numpy()\n",
    "    \n",
    "    # (1, 256, 256, 5) -> (256, 256, 5) \n",
    "    images = np.concatenate(images, axis=1)\n",
    "    masks = np.concatenate(masks, axis=1)\n",
    "    pred = np.concatenate(pred, axis=1)\n",
    "    \n",
    "    # separate s1 / s2\n",
    "    s1_0 = images[:, : , 0] # 1 band image\n",
    "    s1_1 = images[:, : , 1] # 1 band image\n",
    "    s2 = images[:, : , 2:] # color 3 bands image\n",
    "        \n",
    "    fig, ax = plt.subplots(5, 1, figsize=(20, 6))\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    ax[0].imshow(s1_0)\n",
    "    ax[0].set_title('s1_0 Images')    \n",
    "    ax[1].imshow(s1_1)\n",
    "    ax[1].set_title('s1_1 Images')\n",
    "    ax[2].imshow(s2)\n",
    "    ax[2].set_title('s2 Images')\n",
    "    ax[3].imshow(masks, cmap= 'gray')\n",
    "    ax[3].set_title('Masks')\n",
    "    ax[4].imshow(pred, cmap= 'gray')\n",
    "    ax[4].set_title('Predictions')\n",
    "\n",
    "display_batch(images, masks, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697028d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'unet_s1s2_earlyfusion_RGB.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f5a76c",
   "metadata": {},
   "source": [
    "# load previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(5, 1).to(device) # 3 optical bands + 2 radars\n",
    "model.load_state_dict(torch.load(\"/home/llalla/Documents/SWOT/tuto_unet/unet_s1s2_earlyfusion_RGB.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d59467",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(valloader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(images.to(device)).cpu().detach()\n",
    "    pred = pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc5fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move axis for plotting with matplotlib\n",
    "images = images.permute(0, 2, 3, 1)\n",
    "masks = masks.permute(0, 2, 3, 1)\n",
    "pred = pred.permute(0, 2, 3, 1)\n",
    "\n",
    "# convert from tensor to numpy array\n",
    "images = images.numpy()\n",
    "masks = masks.numpy()\n",
    "pred = pred.numpy()\n",
    "\n",
    "# (1, 256, 256, 5) -> (256, 256, 5) \n",
    "images = np.concatenate(images, axis=1)\n",
    "masks = np.concatenate(masks, axis=1)\n",
    "pred = np.concatenate(pred, axis=1)\n",
    "\n",
    "# separate s1 / s2\n",
    "s1_0 = images[:, :, 0] # 1 band image\n",
    "s1_1 = images[:, :, 1] # 1 band image\n",
    "s2 = images[:, :, 2:] # color 3 bands image\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize=(20, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[0].imshow(s1_0)\n",
    "ax[0].set_title('s1_0 Images')    \n",
    "ax[1].imshow(s1_1)\n",
    "ax[1].set_title('s1_1 Images')\n",
    "ax[2].imshow(s2)\n",
    "ax[2].set_title('s2 Images')\n",
    "ax[3].imshow(masks, cmap= 'gray')\n",
    "ax[3].set_title('Masks')\n",
    "ax[4].imshow(pred, cmap= 'gray')\n",
    "ax[4].set_title('Predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
